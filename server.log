nohup: ignoring input
2023-10-14 12:16:57.893959: I tensorflow_serving/model_servers/server.cc:89] Building single TensorFlow model file config:  model_name: fashion_model model_base_path: /workspaces/Leather_QC/model/
2023-10-14 12:16:57.895286: I tensorflow_serving/model_servers/server_core.cc:465] Adding/updating models.
2023-10-14 12:16:57.895394: I tensorflow_serving/model_servers/server_core.cc:594]  (Re-)adding model: fashion_model
2023-10-14 12:16:58.034183: I tensorflow_serving/core/basic_manager.cc:740] Successfully reserved resources to load servable {name: fashion_model version: 1}
2023-10-14 12:16:58.034260: I tensorflow_serving/core/loader_harness.cc:66] Approving load for servable version {name: fashion_model version: 1}
2023-10-14 12:16:58.034528: I tensorflow_serving/core/loader_harness.cc:74] Loading servable version {name: fashion_model version: 1}
2023-10-14 12:16:58.049763: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /workspaces/Leather_QC/model/1
2023-10-14 12:16:58.095951: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:78] Reading meta graph with tags { serve }
2023-10-14 12:16:58.096485: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:119] Reading SavedModel debug info (if present) from: /workspaces/Leather_QC/model/1
2023-10-14 12:16:58.102105: I external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-10-14 12:16:58.337977: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.
2023-10-14 12:16:58.563661: E external/org_tensorflow/tensorflow/core/grappler/optimizers/meta_optimizer.cc:828] tfg_optimizer{} failed: NOT_FOUND: Op type not registered 'DisableCopyOnRead' in binary running on codespaces-ea97fc. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.
	when importing GraphDef to MLIR module in GrapplerHook
2023-10-14 12:16:58.941620: W external/org_tensorflow/tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 15859712 exceeds 10% of free system memory.
2023-10-14 12:16:59.091479: W external/org_tensorflow/tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 15859712 exceeds 10% of free system memory.
2023-10-14 12:16:59.258827: W external/org_tensorflow/tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 15859712 exceeds 10% of free system memory.
2023-10-14 12:16:59.415104: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /workspaces/Leather_QC/model/1
2023-10-14 12:16:59.464907: E external/org_tensorflow/tensorflow/core/grappler/optimizers/meta_optimizer.cc:828] tfg_optimizer{} failed: NOT_FOUND: Op type not registered 'DisableCopyOnRead' in binary running on codespaces-ea97fc. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.
	when importing GraphDef to MLIR module in GrapplerHook
2023-10-14 12:16:59.484261: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 1434502 microseconds.
2023-10-14 12:16:59.486529: I tensorflow_serving/servables/tensorflow/saved_model_warmup_util.cc:59] No warmup data file found at /workspaces/Leather_QC/model/1/assets.extra/tf_serving_warmup_requests
2023-10-14 12:16:59.487919: I tensorflow_serving/core/loader_harness.cc:87] Successfully loaded servable version {name: fashion_model version: 1}
2023-10-14 12:16:59.488692: I tensorflow_serving/model_servers/server_core.cc:486] Finished adding/updating models
2023-10-14 12:16:59.488885: I tensorflow_serving/model_servers/server.cc:133] Using InsecureServerCredentials
2023-10-14 12:16:59.488999: I tensorflow_serving/model_servers/server.cc:391] Profiler service is enabled
2023-10-14 12:16:59.491702: I tensorflow_serving/model_servers/server.cc:417] Running gRPC ModelServer at 0.0.0.0:8500 ...
2023-10-14 12:16:59.493423: I tensorflow_serving/model_servers/server.cc:438] Exporting HTTP/REST API at:localhost:8502 ...
[evhttp_server.cc : 245] NET_LOG: Entering the event loop ...
2023-10-14 12:17:18.713948: E external/org_tensorflow/tensorflow/core/grappler/optimizers/meta_optimizer.cc:828] tfg_optimizer{} failed: NOT_FOUND: Op type not registered 'DisableCopyOnRead' in binary running on codespaces-ea97fc. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.
	when importing GraphDef to MLIR module in GrapplerHook
